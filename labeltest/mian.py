import cv2
import os
import glob
from ultralytics import YOLO


def save_yolo_label(results, img_path, label_dir="labels"):
    """ä¿å­˜YOLOæ ¼å¼æ ‡ç­¾æ–‡ä»¶ï¼ˆå•ä¸ªå›¾ç‰‡ï¼‰"""
    os.makedirs(label_dir, exist_ok=True)
    img_height, img_width = results[0].orig_shape
    # ç”Ÿæˆä¸å›¾ç‰‡åŒåçš„æ ‡ç­¾æ–‡ä»¶è·¯å¾„
    label_name = os.path.splitext(os.path.basename(img_path))[0] + ".txt"
    label_path = os.path.join(label_dir, label_name)

    with open(label_path, 'w') as f:
        for box in results[0].boxes:
            x1, y1, x2, y2 = box.xyxy[0].tolist()  # å·¦ä¸Šè§’å’Œå³ä¸‹è§’åæ ‡
            class_id = int(box.cls)  # ç±»åˆ«ID

            # è®¡ç®—å½’ä¸€åŒ–åæ ‡ï¼ˆYOLOæ ¼å¼è¦æ±‚ï¼‰
            x_center = ((x1 + x2) / 2) / img_width
            y_center = ((y1 + y2) / 2) / img_height
            width = (x2 - x1) / img_width
            height = (y2 - y1) / img_height

            # å†™å…¥æ ‡ç­¾ï¼ˆä¿ç•™6ä½å°æ•°ç²¾åº¦ï¼‰
            f.write(f"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\n")

    print(f"æ ‡ç­¾å·²ä¿å­˜: {label_path}")


def process_single_image(img_path, model, output_img_dir="output_images", output_label_dir="output_labels"):
    """å¤„ç†å•å¼ å›¾ç‰‡ï¼ˆå†…éƒ¨è°ƒç”¨ï¼Œä¾›æ‰¹é‡å¤„ç†ä½¿ç”¨ï¼‰"""
    # è¯»å–å›¾ç‰‡
    img = cv2.imread(img_path)
    if img is None:
        print(f"âŒ è·³è¿‡æ— æ•ˆå›¾ç‰‡: {img_path}")
        return

    # æ¨¡å‹æ¨ç†ï¼ˆç»Ÿä¸€å‚æ•°ï¼‰
    results = model(img, conf=0.25, imgsz=640)  # ç½®ä¿¡åº¦å’Œè¾“å…¥å°ºå¯¸å¯è°ƒæ•´

    # ä¿å­˜æ ‡ç­¾ï¼ˆæ— è®ºæ˜¯å¦æ£€æµ‹åˆ°ç›®æ ‡ï¼Œéƒ½ç”Ÿæˆç©ºæ–‡ä»¶é¿å…åç»­é—æ¼ï¼‰
    os.makedirs(output_label_dir, exist_ok=True)
    save_yolo_label(results, img_path, output_label_dir)

    # ç”Ÿæˆå¹¶ä¿å­˜æ ‡æ³¨åçš„å›¾ç‰‡
    os.makedirs(output_img_dir, exist_ok=True)
    annotated_img = results[0].plot()  # å³ä½¿æ— æ£€æµ‹ç»“æœï¼Œä¹Ÿç”ŸæˆåŸå§‹å›¾å¸¦æ–‡å­—æ ‡æ³¨
    output_img_path = os.path.join(output_img_dir, os.path.basename(img_path))
    cv2.imwrite(output_img_path, annotated_img)
    print(f"âœ… å¤„ç†å®Œæˆ: {output_img_path}")


def process_folder(img_folder, model):
    """æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾ç‰‡"""
    # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼ï¼ˆå¯æ ¹æ®éœ€è¦æ·»åŠ ï¼‰
    img_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.gif']
    img_paths = []
    for ext in img_extensions:
        img_paths.extend(glob.glob(os.path.join(img_folder, ext)))

    if not img_paths:
        print(f"âŒ æœªåœ¨æ–‡ä»¶å¤¹ {img_folder} ä¸­æ‰¾åˆ°å›¾ç‰‡")
        return

    print(f"ğŸ“ æ‰¾åˆ° {len(img_paths)} å¼ å›¾ç‰‡ï¼Œå¼€å§‹æ‰¹é‡å¤„ç†...")
    for i, img_path in enumerate(img_paths, 1):
        print(f"\nå¤„ç†ç¬¬ {i}/{len(img_paths)} å¼ :")
        process_single_image(img_path, model)
    print("\nğŸ“Š æ‰¹é‡å¤„ç†å®Œæˆï¼")


def process_camera(model, camera_id=0):
    """æ‘„åƒå¤´å®æ—¶æ£€æµ‹"""
    cap = cv2.VideoCapture(camera_id)
    while cap.isOpened():
        success, frame = cap.read()
        if not success:
            print("âŒ æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢ï¼Œé€€å‡º")
            break

        # å®æ—¶æ¨ç†
        results = model(frame, conf=0.25, imgsz=640)
        annotated_frame = results[0].plot()

        # æ˜¾ç¤ºç”»é¢
        cv2.imshow("YOLOv8 å®æ—¶æ£€æµ‹", annotated_frame)
        if cv2.waitKey(1) == 27:  # æŒ‰ESCé”®é€€å‡º
            break

    cap.release()
    cv2.destroyAllWindows()


if __name__ == "__main__":
    # åˆå§‹åŒ–æ¨¡å‹ï¼ˆæ›¿æ¢ä¸ºä½ çš„æ¨¡å‹è·¯å¾„ï¼‰
    model = YOLO("yolov8tennis.pt")

    # é€‰æ‹©å¤„ç†æ¨¡å¼
    print("è¯·é€‰æ‹©å¤„ç†æ¨¡å¼ï¼š")
    print("1 - å•å¼ å›¾ç‰‡å¤„ç†")
    print("2 - æ‘„åƒå¤´å®æ—¶æ£€æµ‹")
    print("3 - æ–‡ä»¶å¤¹æ‰¹é‡å¤„ç†")
    mode = input("è¾“å…¥æ¨¡å¼ç¼–å· (1/2/3): ")

    if mode == "1":
        img_path = input("è¯·è¾“å…¥å›¾ç‰‡è·¯å¾„: ").strip()
        # å•å¼ å›¾ç‰‡å¤„ç†æ—¶ï¼Œè¾“å‡ºåˆ°é»˜è®¤æ–‡ä»¶å¤¹
        process_single_image(img_path, model, "single_output", "single_labels")
        # æ˜¾ç¤ºç»“æœï¼ˆå•å¼ æ¨¡å¼ä¸‹é¢å¤–æ˜¾ç¤ºï¼‰
        output_img = cv2.imread(os.path.join("single_output", os.path.basename(img_path)))
        if output_img is not None:
            cv2.imshow("æ£€æµ‹ç»“æœ", output_img)
            cv2.waitKey(5000)  # æ˜¾ç¤º5ç§’åå…³é—­
            cv2.destroyAllWindows()

    elif mode == "2":
        print("ğŸ“¹ å¯åŠ¨æ‘„åƒå¤´å®æ—¶æ£€æµ‹ï¼ˆæŒ‰ESCé€€å‡ºï¼‰...")
        process_camera(model)

    elif mode == "3":
        img_folder = input("è¯·è¾“å…¥å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„: ").strip()
        process_folder(img_folder, model)

    else:
        print("âŒ æ— æ•ˆçš„æ¨¡å¼é€‰æ‹©ï¼Œè¯·è¾“å…¥ 1/2/3")